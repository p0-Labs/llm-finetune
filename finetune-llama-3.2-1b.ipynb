{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n",
        "!huggingface-cli download meta-llama/Llama-3.2-1B-Instruct --exclude \"original/*\" --local-dir meta-llama/Llama-3.2-1B-Instruct\n",
        "!pip install -q datasets trl"
      ],
      "metadata": {
        "id": "yOvNzAfmIQt3"
      },
      "id": "yOvNzAfmIQt3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b1d0a181-6c5d-4f55-baf1-2c9ce20b9273",
      "metadata": {
        "id": "b1d0a181-6c5d-4f55-baf1-2c9ce20b9273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "ab4a559aa506431f94719a49182ff7a1",
            "8b4c7a737a164ee2ab0ca53902657e94",
            "de65d744cef14f098fd997cc8f22b396",
            "276e10c4bfd3407c8c7de37b9f704bc1",
            "bac7f4ca2af04c22af43f0a90941d233",
            "c5658fc0bf3d4faaad2ef6e17dc2fbde",
            "de7191363b3b420dbd4cbe4b664f8068",
            "fe1a9b18cc414eb38ef41d511da88393",
            "690ba787ec234450a37c0e4d272c97ed",
            "b9d3142f44034b4692679d6cba0d3f9f",
            "a25f1498572440e288c3a32cbea28d73"
          ]
        },
        "outputId": "042359f4-54e6-49a7-c89c-e4993596a85d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab4a559aa506431f94719a49182ff7a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "import torch\n",
        "\n",
        "d_opts = [('cuda', torch.cuda.is_available()), ('mps', torch.backends.mps.is_available()), ('cpu', True)]\n",
        "device = next(device for device, available in d_opts if available)\n",
        "print(f'using device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "73f1c961-a1eb-4b4e-b7ef-e4bc0babd4c7",
      "metadata": {
        "id": "73f1c961-a1eb-4b4e-b7ef-e4bc0babd4c7"
      },
      "outputs": [],
      "source": [
        "model_path = 'meta-llama/Llama-3.2-1B-Instruct'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'right'\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upBJ6G-otcEt",
        "outputId": "361ca3c4-7582-4047-8dff-3e40deb7469e"
      },
      "id": "upBJ6G-otcEt",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(128256, 2048)\n",
            "    (layers): ModuleList(\n",
            "      (0-15): 16 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaAttention(\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
            "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
            "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "    (rotary_emb): LlamaRotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b8a3d601-863c-4662-a448-092f2884c355",
      "metadata": {
        "id": "b8a3d601-863c-4662-a448-092f2884c355"
      },
      "outputs": [],
      "source": [
        "dataset_hf_path = 'iamtarun/python_code_instructions_18k_alpaca'\n",
        "dataset = load_dataset(dataset_hf_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'-- data info: {dataset_hf_path} --')\n",
        "print(f'dataset shape: {dataset.shape}')\n",
        "print(f'dataset columns: {dataset.column_names}')\n",
        "print(f'dataset rows: {dataset.num_rows}')\n",
        "print()\n",
        "print('-> example fine-tuning prompt:')\n",
        "print(f\"prompt: {dataset['train'][0]['prompt']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnEAR6Yeu3bh",
        "outputId": "de59a1be-44d6-4d93-8efe-73c7e9244c58"
      },
      "id": "KnEAR6Yeu3bh",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- data info: iamtarun/python_code_instructions_18k_alpaca --\n",
            "dataset shape: {'train': (18612, 4)}\n",
            "dataset columns: {'train': ['instruction', 'input', 'output', 'prompt']}\n",
            "dataset rows: {'train': 18612}\n",
            "\n",
            "-> example fine-tuning prompt:\n",
            "prompt: Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Create a function to calculate the sum of a sequence of integers.\n",
            "\n",
            "### Input:\n",
            "[1, 2, 3, 4, 5]\n",
            "\n",
            "### Output:\n",
            "# Python code\n",
            "def sum_sequence(sequence):\n",
            "  sum = 0\n",
            "  for num in sequence:\n",
            "    sum += num\n",
            "  return sum\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "dec2ff17-6e6a-4b07-8aca-9e8316f683df",
      "metadata": {
        "id": "dec2ff17-6e6a-4b07-8aca-9e8316f683df"
      },
      "outputs": [],
      "source": [
        "def formatting_func(example):\n",
        "    # Combine instruction and input if input is not empty\n",
        "    task = example['instruction']\n",
        "    if example['input']:\n",
        "        task += f\"\\n\\nInput:\\n{example['input']}\"\n",
        "\n",
        "    # Format the prompt\n",
        "    formatted_prompt = f\"### Task:\\n{task}\\n\\n### Response:\\n\"\n",
        "\n",
        "    # Combine the prompt and output\n",
        "    formatted_output = f\"{formatted_prompt}{example['output']}\"\n",
        "\n",
        "    return str({\n",
        "        \"prompt\": formatted_prompt,\n",
        "        \"response\": example['output'],\n",
        "        \"text\": formatted_output\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "pprint.pprint(formatting_func(dataset['train'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r0NAihJzA2t",
        "outputId": "fddbb45a-e005-42f7-c29e-98156814a338"
      },
      "id": "7r0NAihJzA2t",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"{'prompt': '### Task:\\\\nCreate a function to calculate the sum of a sequence \"\n",
            " \"of integers.\\\\n\\\\nInput:\\\\n[1, 2, 3, 4, 5]\\\\n\\\\n### Response:\\\\n', \"\n",
            " \"'response': '# Python code\\\\ndef sum_sequence(sequence):\\\\n  sum = 0\\\\n  for \"\n",
            " \"num in sequence:\\\\n    sum += num\\\\n  return sum', 'text': '### \"\n",
            " 'Task:\\\\nCreate a function to calculate the sum of a sequence of '\n",
            " 'integers.\\\\n\\\\nInput:\\\\n[1, 2, 3, 4, 5]\\\\n\\\\n### Response:\\\\n# Python '\n",
            " 'code\\\\ndef sum_sequence(sequence):\\\\n  sum = 0\\\\n  for num in '\n",
            " \"sequence:\\\\n    sum += num\\\\n  return sum'}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ea77b64-276a-429c-b441-18de2937a227",
      "metadata": {
        "id": "1ea77b64-276a-429c-b441-18de2937a227"
      },
      "outputs": [],
      "source": [
        "# lora + supervised fine-tuning\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias='none',\n",
        "    task_type='CAUSAL_LM'\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "training_args = SFTConfig(\n",
        "    output_dir='./finetuned-llama-3.2-1b-instruct',\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=32,\n",
        "    gradient_accumulation_steps=32,\n",
        "    learning_rate=2e-4,\n",
        "    max_seq_length=512,\n",
        "    label_names=[],\n",
        "    no_cuda=False\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset['train'],\n",
        "    formatting_func=formatting_func,\n",
        "    args=training_args,\n",
        "    processing_class=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc56224f-06b1-4f1b-bcea-0b8d11762117",
      "metadata": {
        "id": "fc56224f-06b1-4f1b-bcea-0b8d11762117"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73af13da-9484-415b-8da0-11bcb10cb3fb",
      "metadata": {
        "id": "73af13da-9484-415b-8da0-11bcb10cb3fb"
      },
      "outputs": [],
      "source": [
        "trainer.model.save_pretrained('./finetuned-llama-3.2-1b')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6f94296-51db-45e7-b36b-0430080b9b35",
      "metadata": {
        "id": "f6f94296-51db-45e7-b36b-0430080b9b35"
      },
      "outputs": [],
      "source": [
        "def generate_chat_response(conversation, max_length=100):\n",
        "    prompt = f\"<s>[INST] {conversation} [/INST]\"\n",
        "    inputs = tokenizer(prompt, return_tensors='pt', padding=True).to(device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_length,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22eded10-fcc9-4aeb-85bc-6ff078851141",
      "metadata": {
        "id": "22eded10-fcc9-4aeb-85bc-6ff078851141"
      },
      "outputs": [],
      "source": [
        "conversation = 'Write a function in python to detect the 13th Friday of a given month and year. The function should accept two parameters: the month (as a number) and the year (as a four-digit number). It should return True if the month contains a Friday the 13th, and False otherwise3.'\n",
        "response = generate_chat_response(conversation, max_length=400)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95008d0a-1e17-401d-bfb7-b40ab32b2364",
      "metadata": {
        "id": "95008d0a-1e17-401d-bfb7-b40ab32b2364"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "notebook_venv",
      "language": "python",
      "name": "notebook_venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab4a559aa506431f94719a49182ff7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b4c7a737a164ee2ab0ca53902657e94",
              "IPY_MODEL_de65d744cef14f098fd997cc8f22b396",
              "IPY_MODEL_276e10c4bfd3407c8c7de37b9f704bc1"
            ],
            "layout": "IPY_MODEL_bac7f4ca2af04c22af43f0a90941d233"
          }
        },
        "8b4c7a737a164ee2ab0ca53902657e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5658fc0bf3d4faaad2ef6e17dc2fbde",
            "placeholder": "​",
            "style": "IPY_MODEL_de7191363b3b420dbd4cbe4b664f8068",
            "value": ""
          }
        },
        "de65d744cef14f098fd997cc8f22b396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe1a9b18cc414eb38ef41d511da88393",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_690ba787ec234450a37c0e4d272c97ed",
            "value": 0
          }
        },
        "276e10c4bfd3407c8c7de37b9f704bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9d3142f44034b4692679d6cba0d3f9f",
            "placeholder": "​",
            "style": "IPY_MODEL_a25f1498572440e288c3a32cbea28d73",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "bac7f4ca2af04c22af43f0a90941d233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5658fc0bf3d4faaad2ef6e17dc2fbde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de7191363b3b420dbd4cbe4b664f8068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe1a9b18cc414eb38ef41d511da88393": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "690ba787ec234450a37c0e4d272c97ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9d3142f44034b4692679d6cba0d3f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a25f1498572440e288c3a32cbea28d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}